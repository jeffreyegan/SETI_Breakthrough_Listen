{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ccad4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import warnings; warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Machine Learning Utilities\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "#import torchvision\n",
    "import timm\n",
    "from timm import create_model\n",
    "\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "#import torch.optim as optim\n",
    "#from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "#from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.learner import _update_first_layer\n",
    "\n",
    "# Image Augmentation\n",
    "#import albumentations\n",
    "#from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587e3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device Type\n",
    "# Device Optimization\n",
    "if torch.cuda.is_available():\n",
    "    device = 'gpu'  # torch.device('cuda')\n",
    "else:\n",
    "    device = 'cpu'  # torch.device('cpu')    \n",
    "#print(f'Using device: {device}')\n",
    "print(f'Using device: '+device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77c45c",
   "metadata": {},
   "source": [
    "Now, lets set a fixed random seed for repeatability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e937320",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(999,reproducible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435802df",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "Now, lets load and inspect the training data's metadata CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69738c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00034abb3629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004300a0b9b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000453852fda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target\n",
       "0  00034abb3629       0\n",
       "1  0004300a0b9b       0\n",
       "2  000453852fda       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('labels','train_labels.csv'))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583596a",
   "metadata": {},
   "source": [
    "Lets now add a column to detail the file path to the actual data file for each entry for the training set metadata and inspect the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e567463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00034abb3629</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/train/0/00034abb3629.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004300a0b9b</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/train/0/0004300a0b9b.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000453852fda</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/train/0/000453852fda.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target                            path\n",
       "0  00034abb3629       0  /data/train/0/00034abb3629.npy\n",
       "1  0004300a0b9b       0  /data/train/0/0004300a0b9b.npy\n",
       "2  000453852fda       0  /data/train/0/000453852fda.npy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = os.path.join('/', 'data', 'train')\n",
    "df['path'] = df['id'].apply(lambda x: train_data_dir+os.path.join('/')+f'{x[0]}/{x}.npy')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe6371",
   "metadata": {},
   "source": [
    "Lets now split the data frame with training data into subsets for training an validation. We'll use a fixed seed to do so in a repeatable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ba566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f0122e",
   "metadata": {},
   "source": [
    "## Generate a Dataset for Pytorch\n",
    "Lets now create an application-specific data class. The data class below enabled both channelized and spatial approaches along with the options to use only the three 'ON' channels or all six channels, including the 'OFF' channels. \n",
    "\n",
    "TODO: The data class may also be improved with some data augmentation routines to increase the datapoints available for training. \n",
    "\n",
    "For this notebook, we will train with the spatial approach that leverages all six channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "028b235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SETIDataset:\n",
    "    def __init__(self, df, spatial=True, sixchan=True):\n",
    "        self.df = df\n",
    "        self.spatial = spatial  # Whether to use a spatial or channelized orrientation\n",
    "        self.sixchan = sixchan  # Whether to use all six channels or just the three 'ON' channels\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.df.iloc[index].target\n",
    "        filename = self.df.iloc[index].path\n",
    "        data = np.load(filename).astype(np.float32)\n",
    "        if not self.sixchan: data = data[::2].astype(np.float32)\n",
    "        if self.spatial:\n",
    "            data = np.vstack(data).transpose((1, 0))\n",
    "            data = cv2.resize(data, dsize=(256,256))     \n",
    "            data_tensor = torch.tensor(data).float().unsqueeze(0)\n",
    "        else:\n",
    "            data = np.transpose(data, (1,2,0))\n",
    "            data = cv2.resize(data, dsize=(256,256))     \n",
    "            data = np.transpose(data, (2, 0, 1)).astype(np.float32)\n",
    "            data_tensor = torch.tensor(data).float()\n",
    "\n",
    "        return (data_tensor, torch.tensor(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cbd028",
   "metadata": {},
   "source": [
    "Lets take our previously created train and validation dataframes and use the `SETIDataset` class to generate data sets suitable for ingestion in a Pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283b3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SETIDataset(train_df)\n",
    "valid_ds = SETIDataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ff0234",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128 # batch size - range from 8 to 128+ depending on available VRAM on the GPU\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=8)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa01961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af939a64",
   "metadata": {},
   "source": [
    "# Training\n",
    "We will use Zachary Mueller's `timm_learner` function to create an already-instantiated `Learner` object with the `DataLoaders` and an appropriately defined CNN model taken from Ross Wightman's amazing `timm` package. The code for `timm_learner` (see the hidden cell below) is based on fastai's `cnn_learner` function. We can tell `timm_learner` what CNN backbone we want to use, as well as the number of input and output channels, and fastai automatically defines the appropriate model. We also pass in the metrics and the loss function. Fastai's default optimizer is AdamW. Finally, we can also use mixed precision training easily.\n",
    "\n",
    "We'll use a simple ImageNet-pretrained ResNext50_32x4d model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ba9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n",
    "    \"Creates a body from any model in the `timm` library.\"\n",
    "    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n",
    "    _update_first_layer(model, n_in, pretrained)\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut): return cut(model)\n",
    "    else: raise NamedError(\"cut must be either integer or function\")\n",
    "\n",
    "def create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n",
    "                     concat_pool=True, **kwargs):\n",
    "    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n",
    "    body = create_timm_body(arch, pretrained, None, n_in)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children()))\n",
    "        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n",
    "    else: head = custom_head\n",
    "    model = nn.Sequential(body, head)\n",
    "    if init is not None: apply_init(model[1], init)\n",
    "    return model\n",
    "\n",
    "def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n",
    "                y_range=None, config=None, n_in=3, n_out=None, normalize=True, **kwargs):\n",
    "    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n",
    "    if config is None: config = {}\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = create_timm_model(arch, n_out, default_split, pretrained, n_in=n_in, y_range=y_range, **config)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n",
    "    if pretrained: learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5f3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(preds,targ):\n",
    "    try: return roc_auc_score(targ.cpu(),preds.squeeze().cpu())\n",
    "    except: return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4618f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnext50_32x4d_ra-d733960d.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d_ra-d733960d.pth\n",
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "learn = timm_learner(dls,'resnext50_32x4d',pretrained=True,n_in=1,n_out=1,metrics=[roc_auc], opt_func=ranger, loss_func=BCEWithLogitsLossFlat()).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045a302",
   "metadata": {},
   "source": [
    "Next, lets employ a fastai function to solve for an optimal learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f59790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='59' class='' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      18.79% [59/314 31:36<2:16:34 1.0428]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fde2b5",
   "metadata": {},
   "source": [
    "The idea is that the learning rate where the loss decreases the most is likely the best learning rate. In this case, this is around ~3e-2.\n",
    "\n",
    "Let's fine-tune the pretrained model using fastai's fit_one_cycle function to train the frozen pretrained model with a one-cycle learning rate schedule. I use high weight decay regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 0.1, cbs=[ReduceLROnPlateau()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a9a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp32()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9f6de",
   "metadata": {},
   "source": [
    "Now lets save our model for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(os.path.join('models', 'resnext50_32x4d-10epochs-128batch'))\n",
    "learn = learn.load(os.path.join('models', 'resnext50_32x4d-10epochs-128batch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490a0a3",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Begin with the metadata file for the test data set and append file paths using the same methods applied to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(os.path.join('labels','sample_submission.csv'))\n",
    "\n",
    "test_dir = os.path.join('/', 'data', 'test')\n",
    "test_df['path'] = test_df['id'].apply(lambda x: test_dir+os.path.join('/')+f'{x[0]}/{x}.npy')\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05dcb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = SETIDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128 # batch size - range from 8 to 128+ depending on available VRAM on the GPU\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=bs, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857845b5",
   "metadata": {},
   "source": [
    "While fastai provides inference functions if we use their specific data API, in this case we used plain PyTorch dataloaders. So we'll just have to iterate over the dataloader and apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beccd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for xb, _ in tqdm(test_dl):\n",
    "    if device == 'gpu':\n",
    "        with torch.no_grad(): output = learn.model(xb.cuda())\n",
    "        preds.append(torch.sigmoid(output.float()).squeeze().cpu())\n",
    "    elif device == 'cpu':\n",
    "        with torch.no_grad(): output = learn.model(xb.cpu())\n",
    "        preds.append(torch.sigmoid(output.float()).squeeze().cpu())\n",
    "    else:\n",
    "        print('device not recognized')\n",
    "preds = torch.cat(preds)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becdc5b",
   "metadata": {},
   "source": [
    "Finally, generate the CSV file detailing the predicted target class for each entry in the Test data set for submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(os.path.join('labels','sample_submission.csv'))\n",
    "sample_df['target'] = preds\n",
    "sample_df.to_csv(os.path.join('labels','resnext50_32x4d-10epochs-128batch.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e35e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "3e96870e7696019b3c1ac48f495cf993b674a7814cf758e88bf510c440c75beb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
